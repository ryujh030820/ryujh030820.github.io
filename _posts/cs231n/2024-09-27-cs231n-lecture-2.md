---
published: true
title: "[CS231n 2강] Image Classification"
author:
  name: JH
  link: https://github.com/ryujh030820
date: 2024-09-28 15:18:00 +0900
categories: [Lecture, CS231N]
tags: [cs231n, computer vision]
math: true
---

## Image Classification이란?

이미지를 보고, 그 이미지가 어떤 카테고리에 속하는지 구분하는 것

### Image Classification의 Challenges

카메라를 옆으로 옮기거나, 조명이 다르거나, 일부밖에 안 보이던가 하는 다양한 변형에도 잘 구분할 수 있어야 하고 클래스 내의 다양성을 다룰 수 있어야 한다. (생김새, 크기, 색 등이 각양각색인 고양이라던가…)

## Data-Driven Approach

![image.png](/assets/img/cs231n-lecture-2/image.png)

고양이는 무엇이다, 물고기는 무엇이다와 같이 손으로 직접 규칙을 써내려가는 대신에 데이터를 수집해 Classifier를 학습시키는 것

## Nearest Neighbor

Train step에서는 단지 모든 학습 데이터를 기억한 후, 가장 유사한 이미지로 레이블링을 예측하는 알고리즘

### L1 Distance

$$
d_I(I_1,I_2)=\sum_{p}|I^{p}_{1}-I^{p}_{2}|
$$

단순히 픽셀 간의 차이를 계산하고 모든 픽셀의 모든 수행 결과를 더한 것으로 이해할 수 있다.

### K-Nearest Neighbors

![image (1).png](</assets/img/cs231n-lecture-2/image (1).png>)

단순히 가장 가까운 이웃을 찾는 것이 아니라 가장 가까운 이웃을 K개만큼 찾고, 이웃끼리 투표를 하는 방법이다.

맨 왼쪽의 경우처럼 초록색 안에 노란색이 침범해있던가 하는 경우를 방지할 수 있다.

### K-Nearest Neighbors: Distance Metric

- L1 (Manhattan) Distance
  $$
  d_I(I_1,I_2)=\sum_{p}|I^{p}_{1}-I^{p}_{2}|
  $$
- L2 (Euclidean) Distance
  $$
  d_I(I_1,I_2)=\sqrt{\sum_{p}(I^{p}_{1}-I^{p}_{2})^2}
  $$

L1은 어떤 좌표 시스템이냐에 따라 많은 영향을 받는다. (당장 좌표축이 회전만 해도 거리가 아예 달라진다.)

따라서 **특징 벡터의 각각 요소들이 개별적인 의미를 가지고 있다면** (ex ) 키, 몸무게) L1 distance가 더 잘 어울릴 수도 있지만, **요소들 간의 실질적인 의미를 잘 모르는 경우라면** L2 distance가 조금은 더 잘 어울릴 수 있다.

## Hyperparameters

K-NN 알고리즘을 사용하려고 한다면 선택해야 하는 몇 가지 항목이 있는데, K와 거리척도가 그 예시다.

### Setting Hyperparameters

![image (2).png](</assets/img/cs231n-lecture-2/image (2).png>)

![image (3).png](</assets/img/cs231n-lecture-2/image (3).png>)

Hyperparameter를 학습시킬 때에는 주로 3번 아이디어를 많이 사용한다.

훈련 세트를 이용해 학습을 시키고, 검증 세트를 이용해 Hyperparameter를 정한다. 테스트 세트는 오직 한 번만 수행한다.

## K-NN을 사용하지 않는 이유

![image (4).png](</assets/img/cs231n-lecture-2/image (4).png>)

실제로는 K-NN을 잘 사용하지는 않는데, 우선 너무 느리다. 학습 단계에서는 빠르지만 테스트 단계에서는 느린 (즉 우리가 원하는 것과 정반대) 알고리즘이기 때문이다.

또 하나의 문제는 L1/L2 Distance가 이미지 간의 거리를 측정하기에 적합하지 않다는 점이다.

예를 들어 원본 이미지에 다양한 변형을 가한 위의 이미지들은 모두 L2 Distance가 똑같다.

![image (5).png](</assets/img/cs231n-lecture-2/image (5).png>)

마지막으로, 차원을 늘릴수록 전체 공간을 조밀하게 커버할 만큼의 트레이닝 샘플의 수가 exponential하게 커진다.

## Linear Classification

![image (6).png](</assets/img/cs231n-lecture-2/image (6).png>)

`Linear classification`은 **parametric model**의 가장 단순한 형태로, data X와 parameter W, 그리고 추가적으로 bias가 존재한다.

bias는 **데이터 독립적으로 각 클래스에 scaling offsets를 더해주는 것**이다.

예를 들어, 고양이 데이터가 개 데이터보다 훨씬 많다면 고양이 클래스에 대응하는 바이어스가 더 커지게 된다.

![image (7).png](</assets/img/cs231n-lecture-2/image (7).png>)

템플릿 매칭의 관점에서 Linear classification을 이해하면, 무엇을 학습하는지 잘 이해할 수 있는데 위의 사진은 CIFAR-10의 각 10개의 카테고리에 해당하는 행 벡터들을 이미지화 시킨 것이다.

가령 맨 왼쪽의 비행기 클래스에 대한 템플릿 이미지는 Linear classifier가 비행기를 분류할 때 푸르스름한 것들을 찾고 있다고 말할 수 있다.

하지만, Linear classification는 클래스 당 하나의 템플릿만 허용하므로 복잡한 문제들을 풀 수 없다.
