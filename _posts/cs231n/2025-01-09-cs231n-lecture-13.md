---
published: true
title: "[CS231n 13강] Generative Models"
date: 2025-01-09 15:04:00 +0900
categories: [Lecture, CS231N]
tags: [cs231n, ai]
math: true
---
## Unsupervised Learning

지금까지는 Supervised Learning에 대해 주로 배웠다.

Supervised Learning에서는 Data x와 Label y가 존재할 때, x → y로 매핑시키는 함수를 찾는 것을 목표로 했다.

그렇다면 Unsupervised Learning이란 무엇일까?

Unsupervised Learning은 Data가 Label 없이 주어졌을 때, **데이터의 숨어있는 기본적인 구조를 학습하는 것을 목표로 학습하는 방법**이다.

그 예로는

- Clustering(군집화)
- Dimensionality Reduction(차원 축소)
- Feature Learning(특징 학습)
- Density Estimation(분포 추정)

등이 있다.

예시를 그림으로 나타내보면 다음과 같다.

![1.png](/assets/img/cs231n-lecture-13/1.png)

Unsupervised Learning이 가지는 장점은 데이터를 많이 모을 수 있다는 것이다. (Labeling 과정이 불필요하므로)

## Generative Models

생성 모델이란 Training Data를 넣어줬을 때, 동일한 분포에서 새로운 샘플들을 생성하는 것을 말한다.

Generative Model도 Unsupervised Learning에 속하는데, 분포 추정(Density Estimation)이 여기서 핵심 문제이다.

Density Estimation을 하는 방법에는 2가지가 있다.

1. Explicit Density Estimation : 생성 모델 $P_{model}(x)$를 명시적으로 나타내주는 방법
2. Implicit Density Estimation : 생성 모델 $P_{model}(x)$를 정의하지 않고 Sample을 얻어내는 방법

Generative Models의 종류를 나타내면 아래와 같다.

![2.png](/assets/img/cs231n-lecture-13/2.png)

이번 강의에서는 다양한 Generative Model들 중

- PixelRNN/CNN
- Variational Autoencoder
- GAN

에 대해서 설명을 한다.

## PixelRNN/CNN

PixelRNN/CNN은 Explicit Density Estimation 중 계산 가능한 density를 다루는 방법 중 하나이다.

Explicit Density Model을 만들기 위해서, Chain Rule을 이용해 Image x를 1차원 분포들 간의 곱의 형태로 분해를 한다.

![3.png](/assets/img/cs231n-lecture-13/3.png)

Pixel Value 간 복잡한 분포들은 Neural Network를 이용하여 표현한다.

그렇다면 “모든 이전 Pixel들”이 의미하는 바가 무엇일까?

이전 Pixel들을 정의하는 데 RNN을 사용하는 방법이 바로 **PixelRNN**이다.

좌측 상단부터 인접한 픽셀들을 이용하여 순차적으로 픽셀을 생성한다. RNN 모델 중에서도 LSTM 모델을 이용한다.

![4.png](/assets/img/cs231n-lecture-13/4.png)

하지만 순차적으로 픽셀들을 생성하기 때문에 굉장히 속도가 느리다는 단점이 있다.

이러한 단점을 보완하기 위해 나온 방법이 **PixelCNN**이다.

RNN 대신 CNN을 이용하여 픽셀을 생성하기 때문에, 병렬적으로 Training이 가능하다. (여전히 Test time에서는 순차적으로 픽셀들을 생성해야 하긴 한다)

PixelRNN과 PixelCNN은 모두 Training Image에 대해 Likelihood(우도)를 최대로 하도록 training을 시킨다.

PixelRNN과 PixelCNN을 요약한 슬라이드는 다음과 같다.

![5.png](/assets/img/cs231n-lecture-13/5.png)

## Variational Autoencoders

앞서 살펴본 PixelCNN 같은 경우 확률 모델이 계산 가능한 함수로 정의가 되어있다.

하지만 VAE는 직접 계산이 불가능한 확률 모델로 정의되어 있다.

따라서 Lower bound(하한선)을 구해서 계산 가능한 형태로 만들어주게 된다.

![6.png](/assets/img/cs231n-lecture-13/6.png)

먼저 VAE를 배우기 전에 Autoencoder의 과정, Encoder와 Decoder가 무엇인지 한 번 알아보자.

Autoencoder는 Deep Neural Network를 이용하여 데이터의 추상화를 위해 사용한다.

**Encoder**란 Input data X가 들어왔을 때, 그 특징 벡터 z를 추출하는 과정을 말한다.

Encoder의 예로는

- Sigmoid
- Fully Connected Layer
- ReLU, CNN

등이 있다.

특징 벡터 z는 보통 Input data X보다 작다. 즉, 차원이 줄어든 형태이다.

그 이유는 Input data에서 중요한 특징들만 담고있는 특징 벡터를 이용하여 z를 구성하고 싶기 때문이다.

다시 말해 Noise라고 생각되는 부분을 제거하고 싶기 때문이다.

![7.png](/assets/img/cs231n-lecture-13/7.png)

그렇다면 어떻게 Feature Representation을 학습할 수 있을까?

바로 원본을 다시 복원(reconstruct)하는 데 사용할 수 있는 특징들을 학습하는 방식을 취한다.

아까 Encoder를 설명했으니 이제 Decoder가 무엇인지 알아보자.

**Decoder**란 특징 벡터 z를 통해 Input data처럼 재구성하는 과정을 말한다.

쉽게 말해 Decoder는 Encoder의 역과정이다.

Decoder의 예도 Encoder의 예와 비슷하다. (하지만 역의 과정을 거친다.)

- Sigmoid
- Fully Connected Layer
- ReLU, CNN(upconv)

복원된 이미지와 원본 이미지의 차이를 계산하기 위해서 L2 loss function을 사용한다.

![8.png](/assets/img/cs231n-lecture-13/8.png)

Decoder는 training할 때만 쓰이고, 실제로 test를 할 때는 Encoder만 가지고 진행한다.

Encoder는 초기에 Supervised learning에 의해 초기화된 모델의 초기값을 이용한다.

즉, Unsupervised learning을 self-supervised learning 문제로 풀 수 있도록 바꾼 것이 AutoEncoder라고 할 수 있다.

VAE는 AutoEncoder가 추출한 특징 벡터를 이용하여 이미지를 재구성할 수는 없을까하는 아이디어에서 나온 방법이다.

VAE를 통해 이미지를 재구성하는 방법에 대해 알아보자.

먼저 학습 데이터가 이는데, 이 학습 데이터는 잠재 변수(특징 벡터) z에 대해서 재구성되는 것이라 가정하자.

강의에서 prior이라는 용어가 자주 나오는데, prior는 확률 분포 관점에서 어떠한 event가 일어날지에 대한 

기대값이라고 한다.

보통 prior를 선택할 때 가우시안 분포를 사용하여 표현한다.

![9.png](/assets/img/cs231n-lecture-13/9.png)

생성 모델을 잘 만들기 위해서는 $\theta^*$의 파라미터 값들을 잘 추정해야 하는데,

여기서 나온 파라미터는 2가지가 있다.

- Prior distribution
- Conditional distribution

Prior distribution 같은 경우 가우시한 함수로 간단하게 표현하지만,

Conditional distribution와 같은 복잡한 함수의 경우 Neural Network를 이용하여 표현한다.

그렇다면 VAE model은 어떻게 training을 시킬까?

우선 $P_{\theta}$를 정의한다.

![10.png](/assets/img/cs231n-lecture-13/10.png)

하지만 여기서 우리가 간과한 사실은 $P_{\theta}$는 계산이 불가능하다는 것이다. (위 식은 적분이 불가능하므로)

따라서 추가적인 encoder를 통해서 학습을 시키는데 $p_{\theta}(z|x)$를 근사한 $q_{\theta}(z|x)$를 이용하여 **샘플링**을 통해 문제를 해결한다.

VAE의 Encoder와 Decoder에 대해서 한 번 알아보자.

AE(AutoEncoder)와 유사한 구조이지만 여기에 확률론적 의미가 추가된다.

Encoder와 Decoder에 대한 Network는 다음과 같다.

![12.png](/assets/img/cs231n-lecture-13/12.png)

이제 Data likelihood 관점으로 다시 돌아오면,

![13.png](/assets/img/cs231n-lecture-13/13.png)

위와 같은 식을 볼 수 있다.

위는 $\log{p_{\theta}}(x^{(i)})$, 즉 로그 가능도에 대한 식을 나타냈는데, 기댓값으로 표현하고 log의 성질에 의해 다음과 같은 3항으로 나눌 수 있다.

여기서 문제가 되는 항이 바로 3번째 항인데 그 이유는 계산이 불가능하기 때문이다.

하지만 KL 발산의 정의에 의해 3번째 항은 0보다 크거나 같으므로 다음 슬라이드와 같이 바꿀 수 있다.

![14.png](/assets/img/cs231n-lecture-13/14.png)

따라서 우리는 앞에 두 항을 하한(lower bound)으로 두고 그래디언트를 이용해 최적화시킨다.

Training의 과정은 다음과 같다.

![15.png](/assets/img/cs231n-lecture-13/15.png)

Test를 할 때는 Decoder network를 이용하여 test를 한다.

![16.png](/assets/img/cs231n-lecture-13/16.png)

서로 독립되어 있는 잠재 변수 z를 통해서 여러 가지 이미지들을 생성할 수 있다.

하지만 생성된 이미지들이 blur한 특징을 갖는 단점이 있다.

![17.png](/assets/img/cs231n-lecture-13/17.png)

VAE는 계산할 수 없는 형태를 계산할 수 있는 형태로 근사시켜 모델을 만든다는 특징이 있다.

하지만 직접 최적화를 진행하는 PixelRNN/CNN보다 만들어진 이미지의 Quality가 떨어진다는 단점이 있다.

## GAN(Generative Adversarial Networks)

GAN은 앞서 살펴본 방법들과는 달리 확률 분포를 계산하지 않고 단지 Sample만을 얻어내는 방법이다.

GAN을 구현하기 위해서는 두 가지의 Network가 필요하다.

- Generator Network
- Discriminator Network

**Generator Network**는 Discriminator를 속여 실제처럼 보이는 가짜 이미지를 만들어 내는 것이 목적이다.

**Discriminator Network**는 진짜 이미지와 가짜 이미지를 구별해내는 것이 목적이다.

GAN의 대략적인 구조는 다음과 같다.

![18.png](/assets/img/cs231n-lecture-13/18.png)

GAN의 object function은 다음과 같다.

![19.png](/assets/img/cs231n-lecture-13/19.png)

Discriminator Network와 Generator Network를 번갈아 가면서 학습을 진행한다.

![20.png](/assets/img/cs231n-lecture-13/20.png)

실제로는 Generator Network의 학습이 제대로 이루어지지 않는데,

$\log{(1-D_{\theta_d}(G_{\theta_g}(z)))}$의 loss landscape를 살펴보면 그 이유를 알 수 있다.

Loss의 값이 작은 경우 기울기가 크기 때문에, 기울기가 Generator가 이미 생성을 잘 하고 있는 지역에만 몰리게 된다.

따라서, 약간의 Trick을 이용하여 Object Function을 바꿔주게 된다.

![21.png](/assets/img/cs231n-lecture-13/21.png)

다른 Network들이 Training을 할 때 batch size를 정해주듯이,

GAN에서는 각 iteration마다 Discriminator를 training할 양을 정해준다.

![22.png](/assets/img/cs231n-lecture-13/22.png)

GAN을 사용해 만든 결과물을 살펴보면, 앞서 살펴본 다른 모델들보다 우수한 것을 확인할 수 있다!

## 참고

<a href="https://taeyoung96.github.io/cs231n/CS231n_13/">https://taeyoung96.github.io/cs231n/CS231n_13/</a>