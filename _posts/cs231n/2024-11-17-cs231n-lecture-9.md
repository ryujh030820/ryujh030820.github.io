---
published: true
title: "[CS231n 9강] CNN Architectures"
date: 2024-11-17 11:41:00 +0900
categories: [Lecture, CS231N]
tags: [cs231n, ai]
math: true
---
## LeNet

![1.png](/assets/img/cs231n-lecture-9/1.png)

**LeNet**은 산업에 성공적으로 적용된 최초의 ConvNet이다.

LeNet은 이미지를 입력으로 받아서 stride = 1인 5x5 필터를 거치고 몇 개의 Conv Layer와 pooling layer를 거친다.

## AlexNet

![2.png](/assets/img/cs231n-lecture-9/2.png)

**AlexNet**은 2012년에 나온 모델이고, 최초의 Large scale CNN이다. ImageNet Classification에서 기존의 non-DNN 모델들을 능가하는 놀라운 성능을 보여줬다.

AlexNet은 기본적으로 conv-pool-normalization 구조가 두 번 반복된 후, conv layer가 조금 더 붙고 . 그 뒤에 pooling layer가 있다. 그리고 마지막에는 FC-layer가 몇 개 붙는다.

## ZFNet

![3.png](/assets/img/cs231n-lecture-9/3.png)

**ZFNet**은 AlexNet의 하이퍼파라미터를 개선한 모델이다. AlexNet과 같은 레이어 수고 기본적인 구조도 같다.

다만, stride 수, filter 수와 같은 하이퍼파라미터를 조절하여 error rate를 더 개선하였다.

## VGGNet

![4.png](/assets/img/cs231n-lecture-9/4.png)

**VGGNet**의 특징은 우선 훨씬 더 깊어졌고, 더 작은 필터를 사용한다는 점이다. AlexNet에서는 8개의 레이어였지만 VGGNet은 16개에서 19개의 레이어를 가진다.

그리고 VGGNet은 항상 3x3 필터만 사용한다. 이는 이웃하는 픽셀을 포함시킬 수 있는 최소 필터이다.

1. **작은 필터를 여러 번 사용한 이유는?**

![5.png](/assets/img/cs231n-lecture-9/5.png)

3x3 필터를 3번 사용한 것과, 처음부터 7x7 필터를 사용한 것을 비교해보자.

위 그림에서 3x3 필터를 2번 거치면, 세번째 피처맵의 한 칸(파란색)은 첫번째 피처맵의 5x5를 바라본 것과 같다.

그리고 이 단계를 한번 더 거치면 네번째 피처맵의 한 칸은 첫번째 피처맵의 7x7 부분을 바라본 것과 같다.

여기서 depth는 표현하지 않았는데, 피처맵의 depth를 C(채널)라고 했을 때, 3x3을 3번할 때의 파라미터 개수는 3*(3^2xC^2) = 27C^2,

7x7 필터인 경우에는 7^2XC^=49C^2으로 파라미터 수는 확 줄어드는 경향이 있다.

1. **VGGNet의 총 파라미터 개수**

![6.png](/assets/img/cs231n-lecture-9/6.png)

그래서 VGG-16의 파라미터 수를 계산하면 위 사진과 같다.

문제점은 파라미터 수가 너무 많다는 것(138M)과, forward pass 시 필요한 전체 메모리(96MB/image)가 너무 크다는 것이다.

파라미터가 존재하는 곳들의 메모리 사용분포를 살펴보면 초기 레이어에서 많은 메모리를 사용하는 것을 알 수 있다. Spatial dimension이 큰 곳들이 메모리를 더 많이 사용한다.

그리고 마지막 레이어는 많은 파라미터를 사용한다. 이 때문에, 최근에 일부 네트워크들은 아예 FC Layer를 없애버리기도 한다.

## GoogLeNet

![7.png](/assets/img/cs231n-lecture-9/7.png)

**GoogLeNet**의 특징은 아래와 같다.

- 더 깊어진 layer
- Inception module이라는 것을 사용함
- FC layer가 사라짐 ⇒ 파라미터 개수가 집중되어 있는 layer를 없애 파라미터 개수를 효과적으로 줄였다.
- 파라미터가 5M개밖에 없다! AlexNet이 6M개인데!

### Inception module

![8.png](/assets/img/cs231n-lecture-9/8.png)

그렇다면 Inception module이란 무엇일까? Inception module이 만들어지게 된 배경을 살펴보면, 그들은 “a good local network topology”를 디자인하고 싶었다.

그래서 network 안에 network라는 개념으로 local topology를 구현했고, 이를 쌓아올렸다.

이 Local network를 Inception Module이라 한다.

**문제점**

- 총 28x28x672 개의 output data가 생성되고, 이를 위해 854M개의 합성곱 연산이 필요하다.
    
    → Inception module 안에서의 계산량이 많다.
    
- **Pooling layer는 feature depth를 유지**하기 때문에 **concatenation은 항상 증가**할 수 밖에 없다.

**⇒ 해결책**

- 계산량을 줄이고 depth를 줄이기 위해 1x1 필터층인 일명 bottle neck layer를 추가한다.

![9.png](/assets/img/cs231n-lecture-9/9.png)

- Inception module 안에 bottle neck layer를 추가해보면 합성곱 계산량이 358M으로 줄어드는 것을 볼 수 있다.
- Pooling layer의 경우에도 depth를 줄이기 위해 1x1 conv layer를 추가하게 되므로, 이를 통해 depth도 줄여 4개의 output을 모두 concatenate한 depth 또한 줄일 수 있다.

### 전체 네트워크 구조

![10.png](/assets/img/cs231n-lecture-9/10.png)

전체 구조는 위 사진과 같다. 초반에는 우리가 일반적으로 보던 레이어들로 구성되어 있다.

중반부에는 inception module이 쌓아져 있고, 결론적으로 classifier output이 나오게 된다.

하나 더 봐야 할 것은 GoogLeNet 같은 경우 auxiliary classifier가 존재한다.

네모 친 미니 네트워크들에서도 loss를 계산하는데, 이는 전체 네트워크가 깊기 때문에 그래디언트 값이 점점 작아져 0이 되는 것(gradient vanishing)을 방지하여 중간 레이어들의 학습을 도와주는 역할을 한다.

추가적으로, 추론 단계에서는 메인 분류기의 결과만을 사용한다.

## ResNet

![11.png](/assets/img/cs231n-lecture-9/11.png)

마지막으로 **ResNet**의 특징은 아래와 같다.

- 152층으로 획기적으로 깊어졌다. ILSVRC’15와 COCO’15 분류 대회에서 모두 우승했다.
- ResNet의 이름은 Residual Network로, layer가 깊어질 때 생기는 gradient vanishing 문제를 residual block이라는 방식을 통해 해결하고자 한 데에서 착안한 이름이다.

**Q. CNN을 깊고 더 깊게 쌓게 되면 어떤 일이 벌어질까?**

![12.png](/assets/img/cs231n-lecture-9/12.png)

위의 그래프를 보면 test error의 경우 56-layer가 20-layer보다 안 좋다.

하지만 이상한 것은 training error을 살펴보면, 56-layer에서 더 많은 파라미터가 있음에도 불구하고 overfit이 되지 않고 training error가 높은 것을 볼 수 있다.

ResNet의 저자들은 이것을 optimization의 문제, 즉 모델이 깊어질수록 최적화가 어려워지기 때문이라고 생각했다.

![13.png](/assets/img/cs231n-lecture-9/13.png)

그들은 또한 모델이 깊다면 최소한 더 shallow한 모델의 성능만큼은 나와야 하지 않는지에 대한 의문을 제기했다. 이러한 생각으로부터 residual mapping 아이디어가 창안되었다.

그들은 output H(x)를 학습시키는 것보다 **변화량 F(x)**를 학습시키는 것이 더 쉬울 것이라 판단, 오른쪽의 커브 화살표인 skip connection을 추가하여 구성했다.

Residual이 학습이 더 잘 되냐?는 가설일 뿐이지만 그들은 레이어가 잘 동작하려면 레이어의 출력이 identity에 가까워야 한다는 가설을 세우고 진행했다.

![14.png](/assets/img/cs231n-lecture-9/14.png)

![15.png](/assets/img/cs231n-lecture-9/15.png)

전체 ResNet 아키텍처는 위 첫번째 사진과 같으며, depth가 50 이상일 때는 bottleneck layer를 추가하여 3x3 conv의 연산량을 줄인다.

## 참고

https://bookandmed.tistory.com/58

https://oculus.tistory.com/14